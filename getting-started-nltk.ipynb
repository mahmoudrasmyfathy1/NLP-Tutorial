{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nNLTK (Natural Language Toolkit), one of the most popular libraries in Python for working with human language data (i.e., text). This tutorial will guide you through the installation process, basic concepts, and some key functionalities of NLTK.","metadata":{}},{"cell_type":"markdown","source":"# 1.Installation\nFirst, you need to install NLTK. You can do this easily using pip. In your command line (Terminal, Command Prompt, etc.), enter the following command:","metadata":{}},{"cell_type":"code","source":"!pip install nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-27T21:05:13.127527Z","iopub.execute_input":"2024-01-27T21:05:13.127962Z","iopub.status.idle":"2024-01-27T21:05:28.822341Z","shell.execute_reply.started":"2024-01-27T21:05:13.127915Z","shell.execute_reply":"2024-01-27T21:05:28.821387Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2.Understanding the Role of nltk.download() in NLTK Setup\nUse nltk.download() to fetch datasets and models for text processing with NLTK, ensuring updated resources and easing setup. ","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.Tokenization\nTokenization is the process of splitting a text into meaningful units, such as words or sentences.","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize, sent_tokenize\n\ntext = \"Hello there! How are you? I hope you're learning a lot from this tutorial.\"\n\n# Sentence Tokenization\nsentences = sent_tokenize(text)\nprint(sentences)\n\n# Word Tokenization\nwords = word_tokenize(text)\nprint(words)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T18:42:51.624994Z","iopub.execute_input":"2024-01-27T18:42:51.625465Z","iopub.status.idle":"2024-01-27T18:42:51.651612Z","shell.execute_reply.started":"2024-01-27T18:42:51.625432Z","shell.execute_reply":"2024-01-27T18:42:51.650532Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['Hello there!', 'How are you?', \"I hope you're learning a lot from this tutorial.\"]\n['Hello', 'there', '!', 'How', 'are', 'you', '?', 'I', 'hope', 'you', \"'re\", 'learning', 'a', 'lot', 'from', 'this', 'tutorial', '.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 4. Part-of-Speech (POS) Tagging\n\nPOS tagging means labeling words with their part of speech (noun, verb, adjective, etc.).","metadata":{}},{"cell_type":"code","source":"from nltk import pos_tag\n\nwords = word_tokenize(\"I am learning NLP with NLTK\")\npos_tags = pos_tag(words)\nprint(pos_tags)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T18:44:19.297434Z","iopub.execute_input":"2024-01-27T18:44:19.297926Z","iopub.status.idle":"2024-01-27T18:44:19.466261Z","shell.execute_reply.started":"2024-01-27T18:44:19.297892Z","shell.execute_reply":"2024-01-27T18:44:19.464923Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[('I', 'PRP'), ('am', 'VBP'), ('learning', 'VBG'), ('NLP', 'NNP'), ('with', 'IN'), ('NLTK', 'NNP')]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5. Stopwords\nStopwords are common words that are usually removed from text because they carry little meaningful information.","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\n\nwords = word_tokenize(\"Hello there! How are you? I hope you're learning a lot from this tutorial.\")\nstop_words = set(stopwords.words('english'))\nfiltered_words = [word for word in words if not word in stop_words]\nprint(filtered_words)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T22:18:02.835040Z","iopub.execute_input":"2024-01-27T22:18:02.835414Z","iopub.status.idle":"2024-01-27T22:18:02.844096Z","shell.execute_reply.started":"2024-01-27T22:18:02.835386Z","shell.execute_reply":"2024-01-27T22:18:02.842847Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"['Hello', '!', 'How', '?', 'I', 'hope', \"'re\", 'learning', 'lot', 'tutorial', '.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 6. Stemming\nStemming is a process of stripping suffixes from words to extract the base or root form, known as the 'stem'. For example, the stem of the words 'waiting', 'waited', and 'waits' is 'wait'.","metadata":{}},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nps = PorterStemmer()\nsentence = \"It's important to be waiting patiently when you're learning to code.\"\nwords = word_tokenize(sentence)\nstemmed_words = [ps.stem(word) for word in words]\nprint(stemmed_words)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T21:31:48.286768Z","iopub.execute_input":"2024-01-27T21:31:48.287531Z","iopub.status.idle":"2024-01-27T21:31:48.295182Z","shell.execute_reply.started":"2024-01-27T21:31:48.287495Z","shell.execute_reply":"2024-01-27T21:31:48.293997Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['It', \"'s\", 'import', 'to', 'be', 'wait', 'patient', 'when', 'you', \"'re\", 'learn', 'to', 'code', '.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 7. Lemmatization\nLemmatization is the process of reducing a word to its base or dictionary form, known as the 'lemma'. Unlike stemming, lemmatization considers the context and converts the word to its meaningful base form. For instance, 'is', 'are', and 'am' would all be lemmatized to 'be'.\n","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('punkt')\nnltk.download('wordnet', download_dir='/usr/share/nltk_data/corpora/wordnet')  # specify your NLTK data directory if it's not in the default location\n\nlemmatizer = WordNetLemmatizer()\nsentence = \"The leaves on the ground were raked by the gardener, who was also planting bulbs for the coming spring.\"\nwords = word_tokenize(sentence)\nlemmatized_words = [lemmatizer.lemmatize(word) for word in words]\nprint(lemmatized_words)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T21:50:22.374015Z","iopub.execute_input":"2024-01-27T21:50:22.374399Z","iopub.status.idle":"2024-01-27T21:50:22.409188Z","shell.execute_reply.started":"2024-01-27T21:50:22.374371Z","shell.execute_reply":"2024-01-27T21:50:22.408042Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /usr/share/nltk_data/corpora/wordnet...\n[nltk_data]   Package wordnet is already up-to-date!\n['The', 'leaf', 'on', 'the', 'ground', 'were', 'raked', 'by', 'the', 'gardener', ',', 'who', 'wa', 'also', 'planting', 'bulb', 'for', 'the', 'coming', 'spring', '.']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 8.Frequency Distribution\nThis is used to find the frequency of each vocabulary item in the text.","metadata":{}},{"cell_type":"code","source":"from nltk.probability import FreqDist\nwords = word_tokenize(\"I need to write a very, very simple sentence\")\nfdist = FreqDist(words)\nprint(fdist.most_common(1))","metadata":{"execution":{"iopub.status.busy":"2024-01-27T21:53:57.558657Z","iopub.execute_input":"2024-01-27T21:53:57.559182Z","iopub.status.idle":"2024-01-27T21:53:57.567244Z","shell.execute_reply.started":"2024-01-27T21:53:57.559139Z","shell.execute_reply":"2024-01-27T21:53:57.566154Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[('very', 2)]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 9. Named Entity Recognition (NER\n","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tag import pos_tag\nfrom nltk.chunk import ne_chunk\n\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('maxent_ne_chunker')\nnltk.download('words')\n\nsentence = \"I will travel to Spain\"\n# Tokenize the sentence\nwords = word_tokenize(sentence)\n# Part-of-speech tagging\npos_tags = pos_tag(words)\n# Named entity recognition\nnamed_entities = ne_chunk(pos_tags)\n# Print named entities\nprint(named_entities)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T22:15:34.796488Z","iopub.execute_input":"2024-01-27T22:15:34.796878Z","iopub.status.idle":"2024-01-27T22:15:34.808404Z","shell.execute_reply.started":"2024-01-27T22:15:34.796847Z","shell.execute_reply":"2024-01-27T22:15:34.807220Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package words to /usr/share/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n(S I/PRP will/MD travel/VB to/TO (GPE Spain/NNP))\n","output_type":"stream"}]}]}